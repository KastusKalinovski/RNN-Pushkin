{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T12:51:46.711009Z",
     "start_time": "2020-03-22T12:51:46.708854Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T12:52:40.332504Z",
     "start_time": "2020-03-22T12:52:40.284859Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('onegin.txt', 'r', encoding=\"utf8\") as f:\n",
    "    text=f.read()\n",
    "vocab = sorted(set(text))\n",
    "vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
    "int_to_vocab = dict(enumerate(vocab))\n",
    "encoded = np.array([vocab_to_int[c] for c in text], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T12:52:40.578134Z",
     "start_time": "2020-03-22T12:52:40.574139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T12:52:41.041004Z",
     "start_time": "2020-03-22T12:52:41.034996Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_batches(arr,n_seqs,n_steps):\n",
    "    '''Создаем генератор, который возвращает пакеты размером\n",
    "       n_seqs x n_steps из массива arr.\n",
    "       \n",
    "       Аргументы\n",
    "       ---------\n",
    "       arr: Массив, из которого получаем пакеты\n",
    "       n_seqs: Batch size, количество последовательностей в пакете\n",
    "       n_steps: Sequence length, сколько \"шагов\" делаем в пакете\n",
    "    '''\n",
    "    # Считаем количество символов на пакет и количество пакетов, которое можем сформировать\n",
    "    characters_per_batch = n_seqs * n_steps\n",
    "    n_batches = len(arr)//characters_per_batch  \n",
    "    \n",
    "    # Сохраняем в массиве только символы, которые позволяют сформировать целое число пакетов\n",
    "    arr = arr[:n_batches * characters_per_batch]\n",
    "    \n",
    "    # Делаем reshape 1D -> 2D, используя n_seqs как число строк, как на картинке\n",
    "    arr = arr.reshape((n_seqs, -1))\n",
    "    \n",
    "    for n in range(0, arr.shape[1], n_steps):\n",
    "        # пакет данных, который будет подаваться на вход сети\n",
    "        x = arr[:, n:n+n_steps]\n",
    "        # целевой пакет, с которым будем сравнивать предсказание, получаем сдвиганием \"x\" на один символ вперед\n",
    "        y = np.zeros_like(x)\n",
    "        y[:, :-1], y[:, -1] = x[:, 1:], x[:, 0]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T12:52:41.754457Z",
     "start_time": "2020-03-22T12:52:41.749472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      " [[ 32  54   1 121 136]\n",
      " [123 113 123 118   8]\n",
      " [109 126 137  21   0]\n",
      " [122 114 127   6   1]\n",
      " [111 109 120   1 123]]\n",
      "\n",
      "y\n",
      " [[ 54   1 121 136 126]\n",
      " [113 123 118   8   0]\n",
      " [126 137  21   0   0]\n",
      " [114 127   6   1 138]\n",
      " [109 120   1 123 122]]\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(encoded, 10, 50)\n",
    "x, y = next(batches)\n",
    "print('x\\n', x[:5, :5])\n",
    "print('\\ny\\n', y[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T12:52:42.253739Z",
     "start_time": "2020-03-22T12:52:42.249776Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_inputs(batch_size, num_steps):\n",
    "    ''' Определяем placeholder'ы для входных, целевых данных, а также вероятности drop out\n",
    "    \n",
    "        Аргументы\n",
    "        ---------\n",
    "        batch_size: Batch size, количество последовательностей в пакете\n",
    "        num_steps: Sequence length, сколько \"шагов\" делаем в пакете\n",
    "        \n",
    "    '''\n",
    "    # Объявляем placeholder'ы\n",
    "    inputs = tf.placeholder(tf.int32, [batch_size, num_steps], name='inputs')\n",
    "    targets = tf.placeholder(tf.int32, [batch_size, num_steps], name='targets')\n",
    "    \n",
    "    # Placeholder для вероятности drop out\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return inputs, targets, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T12:52:42.704881Z",
     "start_time": "2020-03-22T12:52:42.698897Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_lstm(lstm_size, num_layers, batch_size, keep_prob):\n",
    "    ''' Строим LSTM ячейку.\n",
    "    \n",
    "        Аргументы\n",
    "        ---------\n",
    "        keep_prob: Скаляр (tf.placeholder) для dropout keep probability\n",
    "        lstm_size: Размер скрытых слоев в LSTM ячейках\n",
    "        num_layers: Количество LSTM слоев\n",
    "        batch_size: Batch size\n",
    "\n",
    "    '''\n",
    "    def build_cell(lstm_size, keep_prob):\n",
    "        # Начинаем с базовой LSTM ячейки\n",
    "        lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "        \n",
    "        # Добавляем dropout к ячейке\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "        return drop\n",
    "    \n",
    "    # Стэкируем несколько LSTM слоев для придания глубины нашему deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([build_cell(lstm_size, keep_prob) for _ in range(num_layers)])\n",
    "    # Инициализируем начальное состояние LTSM ячейки\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    return cell, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T12:52:42.975822Z",
     "start_time": "2020-03-22T12:52:42.970835Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_output(lstm_output, in_size, out_size):\n",
    "    ''' Строим softmax слой и возвращаем результат его работы.\n",
    "    \n",
    "        Аргументы\n",
    "        ---------\n",
    "        \n",
    "        x: Входящий от LSTM тензор\n",
    "        in_size: Размер входящего тензора, (кол-во LSTM юнитов скрытого слоя)\n",
    "        out_size: Размер softmax слоя (объем словаря)\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # вытягиваем и решэйпим тензор, выполняя преобразование 3D -> 2D\n",
    "    seq_output = tf.concat(lstm_output, axis=1)\n",
    "    x = tf.reshape(seq_output, [-1, in_size])\n",
    "    \n",
    "    # Соединяем результат LTSM слоев с softmax слоем\n",
    "    with tf.variable_scope('softmax'):\n",
    "        softmax_w = tf.Variable(tf.truncated_normal((in_size, out_size), stddev=0.1))\n",
    "        softmax_b = tf.Variable(tf.zeros(out_size))\n",
    "    \n",
    "    # Считаем logit-функцию\n",
    "    logits = tf.matmul(x, softmax_w) + softmax_b\n",
    "    # Используем функцию softmax для получения предсказания\n",
    "    out = tf.nn.softmax(logits, name='predictions')\n",
    "    \n",
    "    return out, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T12:52:43.299582Z",
     "start_time": "2020-03-22T12:52:43.295592Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_loss(logits, targets, lstm_size, num_classes):\n",
    "    ''' Считаем функцию потери на основании значений logit-функции и целевых значений.\n",
    "    \n",
    "        Аргументы\n",
    "        ---------\n",
    "        logits: значение logit-функции\n",
    "        targets: целевые значения, с которыми сравниваем предсказания\n",
    "        lstm_size: Количество юнитов в LSTM слое\n",
    "        num_classes: Количество классов в целевых значениях (размер словаря)\n",
    "        \n",
    "    '''\n",
    "    # Делаем one-hot кодирование целевых значений и решейпим по образу и подобию logits\n",
    "    y_one_hot = tf.one_hot(targets, num_classes)\n",
    "    y_reshaped = tf.reshape(y_one_hot, logits.get_shape())\n",
    "    \n",
    "    # Считаем значение функции потери softmax cross entropy loss и возвращаем среднее значение\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_reshaped)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T12:52:43.711746Z",
     "start_time": "2020-03-22T12:52:43.707757Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_optimizer(loss, learning_rate, grad_clip):\n",
    "    ''' Строим оптимизатор для обучения, используя обрезку градиента.\n",
    "    \n",
    "        Arguments:\n",
    "        loss: значение функции потери\n",
    "        learning_rate: параметр скорости обучения\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Оптимизатор для обучения, обрезка градиента для контроля \"взрывающихся\" градиентов\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T12:52:44.331480Z",
     "start_time": "2020-03-22T12:52:44.326274Z"
    }
   },
   "outputs": [],
   "source": [
    "class CharRNN:\n",
    "    \n",
    "    def __init__(self, num_classes, batch_size=64, num_steps=50, \n",
    "                       lstm_size=128, num_layers=2, learning_rate=0.001, \n",
    "                       grad_clip=5, sampling=False):\n",
    "    \n",
    "        # Мы будем использовать эту же сеть для сэмплирования (генерации текста),\n",
    "        # при этом будем подавать по одному символу за один раз\n",
    "        if sampling == True:\n",
    "            batch_size, num_steps = 1, 1\n",
    "        else:\n",
    "            batch_size, num_steps = batch_size, num_steps\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # Получаем input placeholder'ы\n",
    "        self.inputs, self.targets, self.keep_prob = build_inputs(batch_size, num_steps)\n",
    "\n",
    "        # Строим LSTM ячейку\n",
    "        cell, self.initial_state = build_lstm(lstm_size, num_layers, batch_size, self.keep_prob)\n",
    "\n",
    "        ### Прогоняем данные через RNN слои\n",
    "        # Делаем one-hot кодирование входящих данных\n",
    "        x_one_hot = tf.one_hot(self.inputs, num_classes)\n",
    "        \n",
    "        # Прогоняем данные через RNN и собираем результаты\n",
    "        outputs, state = tf.nn.dynamic_rnn(cell, x_one_hot, initial_state=self.initial_state)\n",
    "        self.final_state = state\n",
    "        \n",
    "        # Получаем предсказания (softmax) и результат logit-функции\n",
    "        self.prediction, self.logits = build_output(outputs, lstm_size, num_classes)\n",
    "        \n",
    "        # Считаем потери и оптимизируем (с обрезкой градиента)\n",
    "        self.loss = build_loss(self.logits, self.targets, lstm_size, num_classes)\n",
    "        self.optimizer = build_optimizer(self.loss, learning_rate, grad_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T12:52:45.966874Z",
     "start_time": "2020-03-22T12:52:45.962887Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 100        # Размер пакета\n",
    "num_steps = 100         # Шагов в пакете\n",
    "lstm_size = 512         # Количество LSTM юнитов в скрытом слое\n",
    "num_layers = 2          # Количество LSTM слоев\n",
    "learning_rate = 0.001   # Скорость обучения\n",
    "keep_prob = 0.5         # Dropout keep probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-20T12:29:10.834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001F324DB3288>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001F324DB3288>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001F324DB3288>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001F324DB3288>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000001F324E9F988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000001F324E9F988>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000001F324E9F988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000001F324E9F988>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000001F3255C2B88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000001F3255C2B88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000001F3255C2B88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000001F3255C2B88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Epoch: 1/100...  Training Step: 1...  Training loss: 4.9985...  1.8924 sec/batch\n",
      "Epoch: 1/100...  Training Step: 2...  Training loss: 4.9372...  1.7500 sec/batch\n",
      "Epoch: 1/100...  Training Step: 3...  Training loss: 4.5914...  1.8050 sec/batch\n",
      "Epoch: 1/100...  Training Step: 4...  Training loss: 5.1673...  1.7510 sec/batch\n",
      "Epoch: 1/100...  Training Step: 5...  Training loss: 4.2192...  1.7686 sec/batch\n",
      "Epoch: 1/100...  Training Step: 6...  Training loss: 4.1412...  2.4027 sec/batch\n",
      "Epoch: 1/100...  Training Step: 7...  Training loss: 4.0313...  2.8782 sec/batch\n",
      "Epoch: 1/100...  Training Step: 8...  Training loss: 3.9251...  2.6238 sec/batch\n",
      "Epoch: 1/100...  Training Step: 9...  Training loss: 3.8325...  2.8272 sec/batch\n",
      "Epoch: 1/100...  Training Step: 10...  Training loss: 3.7844...  2.8783 sec/batch\n",
      "Epoch: 1/100...  Training Step: 11...  Training loss: 3.7554...  2.5643 sec/batch\n",
      "Epoch: 1/100...  Training Step: 12...  Training loss: 3.7051...  2.4892 sec/batch\n",
      "Epoch: 1/100...  Training Step: 13...  Training loss: 3.7086...  2.5383 sec/batch\n",
      "Epoch: 1/100...  Training Step: 14...  Training loss: 3.7142...  2.5479 sec/batch\n",
      "Epoch: 1/100...  Training Step: 15...  Training loss: 3.6509...  2.6335 sec/batch\n",
      "Epoch: 1/100...  Training Step: 16...  Training loss: 3.6601...  2.6298 sec/batch\n",
      "Epoch: 1/100...  Training Step: 17...  Training loss: 3.6219...  2.5939 sec/batch\n",
      "Epoch: 2/100...  Training Step: 18...  Training loss: 3.7258...  2.5593 sec/batch\n",
      "Epoch: 2/100...  Training Step: 19...  Training loss: 3.6243...  2.7302 sec/batch\n",
      "Epoch: 2/100...  Training Step: 20...  Training loss: 3.6247...  2.8268 sec/batch\n",
      "Epoch: 2/100...  Training Step: 21...  Training loss: 3.6446...  2.8157 sec/batch\n",
      "Epoch: 2/100...  Training Step: 22...  Training loss: 3.6261...  2.5808 sec/batch\n",
      "Epoch: 2/100...  Training Step: 23...  Training loss: 3.6548...  2.6367 sec/batch\n",
      "Epoch: 2/100...  Training Step: 24...  Training loss: 3.6307...  2.5517 sec/batch\n",
      "Epoch: 2/100...  Training Step: 25...  Training loss: 3.6002...  2.7085 sec/batch\n",
      "Epoch: 2/100...  Training Step: 26...  Training loss: 3.5877...  2.5826 sec/batch\n",
      "Epoch: 2/100...  Training Step: 27...  Training loss: 3.5888...  2.5826 sec/batch\n",
      "Epoch: 2/100...  Training Step: 28...  Training loss: 3.5939...  2.5621 sec/batch\n",
      "Epoch: 2/100...  Training Step: 29...  Training loss: 3.5612...  2.4869 sec/batch\n",
      "Epoch: 2/100...  Training Step: 30...  Training loss: 3.5617...  2.4195 sec/batch\n",
      "Epoch: 2/100...  Training Step: 31...  Training loss: 3.5683...  2.7093 sec/batch\n",
      "Epoch: 2/100...  Training Step: 32...  Training loss: 3.5377...  2.4340 sec/batch\n",
      "Epoch: 2/100...  Training Step: 33...  Training loss: 3.5580...  2.3996 sec/batch\n",
      "Epoch: 2/100...  Training Step: 34...  Training loss: 3.5208...  2.6081 sec/batch\n",
      "Epoch: 3/100...  Training Step: 35...  Training loss: 3.6211...  2.5933 sec/batch\n",
      "Epoch: 3/100...  Training Step: 36...  Training loss: 3.5292...  2.5632 sec/batch\n",
      "Epoch: 3/100...  Training Step: 37...  Training loss: 3.5366...  2.6434 sec/batch\n",
      "Epoch: 3/100...  Training Step: 38...  Training loss: 3.5646...  2.4190 sec/batch\n",
      "Epoch: 3/100...  Training Step: 39...  Training loss: 3.5430...  2.4096 sec/batch\n",
      "Epoch: 3/100...  Training Step: 40...  Training loss: 3.5761...  2.4036 sec/batch\n",
      "Epoch: 3/100...  Training Step: 41...  Training loss: 3.5611...  2.4964 sec/batch\n",
      "Epoch: 3/100...  Training Step: 42...  Training loss: 3.5373...  2.6641 sec/batch\n",
      "Epoch: 3/100...  Training Step: 43...  Training loss: 3.5267...  2.6404 sec/batch\n",
      "Epoch: 3/100...  Training Step: 44...  Training loss: 3.5174...  2.4410 sec/batch\n",
      "Epoch: 3/100...  Training Step: 45...  Training loss: 3.5125...  2.4155 sec/batch\n",
      "Epoch: 3/100...  Training Step: 46...  Training loss: 3.4803...  2.4719 sec/batch\n",
      "Epoch: 3/100...  Training Step: 47...  Training loss: 3.4950...  2.9157 sec/batch\n",
      "Epoch: 3/100...  Training Step: 48...  Training loss: 3.5318...  2.8300 sec/batch\n",
      "Epoch: 3/100...  Training Step: 49...  Training loss: 3.5870...  2.6699 sec/batch\n",
      "Epoch: 3/100...  Training Step: 50...  Training loss: 3.5928...  2.7447 sec/batch\n",
      "Epoch: 3/100...  Training Step: 51...  Training loss: 3.5219...  2.5933 sec/batch\n",
      "Epoch: 4/100...  Training Step: 52...  Training loss: 3.5189...  2.5537 sec/batch\n",
      "Epoch: 4/100...  Training Step: 53...  Training loss: 3.4563...  2.5637 sec/batch\n",
      "Epoch: 4/100...  Training Step: 54...  Training loss: 3.4545...  2.5552 sec/batch\n",
      "Epoch: 4/100...  Training Step: 55...  Training loss: 3.4889...  2.5716 sec/batch\n",
      "Epoch: 4/100...  Training Step: 56...  Training loss: 3.4627...  2.5565 sec/batch\n",
      "Epoch: 4/100...  Training Step: 57...  Training loss: 3.4856...  2.5776 sec/batch\n",
      "Epoch: 4/100...  Training Step: 58...  Training loss: 3.4628...  2.5736 sec/batch\n",
      "Epoch: 4/100...  Training Step: 59...  Training loss: 3.4435...  2.6080 sec/batch\n",
      "Epoch: 4/100...  Training Step: 60...  Training loss: 3.4220...  2.6385 sec/batch\n",
      "Epoch: 4/100...  Training Step: 61...  Training loss: 3.4238...  2.6677 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/100...  Training Step: 62...  Training loss: 3.4218...  2.6197 sec/batch\n",
      "Epoch: 4/100...  Training Step: 63...  Training loss: 3.3923...  2.5727 sec/batch\n",
      "Epoch: 4/100...  Training Step: 64...  Training loss: 3.4138...  2.5766 sec/batch\n",
      "Epoch: 4/100...  Training Step: 65...  Training loss: 3.4075...  2.5881 sec/batch\n",
      "Epoch: 4/100...  Training Step: 66...  Training loss: 3.3761...  2.6335 sec/batch\n",
      "Epoch: 4/100...  Training Step: 67...  Training loss: 3.3731...  2.7188 sec/batch\n",
      "Epoch: 4/100...  Training Step: 68...  Training loss: 3.3540...  2.6876 sec/batch\n",
      "Epoch: 5/100...  Training Step: 69...  Training loss: 3.4408...  2.6838 sec/batch\n",
      "Epoch: 5/100...  Training Step: 70...  Training loss: 3.3573...  2.6406 sec/batch\n",
      "Epoch: 5/100...  Training Step: 71...  Training loss: 3.3652...  2.6374 sec/batch\n",
      "Epoch: 5/100...  Training Step: 72...  Training loss: 3.3862...  2.6958 sec/batch\n",
      "Epoch: 5/100...  Training Step: 73...  Training loss: 3.3704...  2.7286 sec/batch\n",
      "Epoch: 5/100...  Training Step: 74...  Training loss: 3.3892...  2.6389 sec/batch\n",
      "Epoch: 5/100...  Training Step: 75...  Training loss: 3.3602...  2.5627 sec/batch\n",
      "Epoch: 5/100...  Training Step: 76...  Training loss: 3.3481...  2.5714 sec/batch\n",
      "Epoch: 5/100...  Training Step: 77...  Training loss: 3.3343...  2.5747 sec/batch\n",
      "Epoch: 5/100...  Training Step: 78...  Training loss: 3.3290...  2.5881 sec/batch\n",
      "Epoch: 5/100...  Training Step: 79...  Training loss: 3.3217...  2.5627 sec/batch\n",
      "Epoch: 5/100...  Training Step: 80...  Training loss: 3.3033...  2.5555 sec/batch\n",
      "Epoch: 5/100...  Training Step: 81...  Training loss: 3.3336...  2.7926 sec/batch\n",
      "Epoch: 5/100...  Training Step: 82...  Training loss: 3.2980...  2.6459 sec/batch\n",
      "Epoch: 5/100...  Training Step: 83...  Training loss: 3.2807...  2.6155 sec/batch\n",
      "Epoch: 5/100...  Training Step: 84...  Training loss: 3.2872...  2.6036 sec/batch\n",
      "Epoch: 5/100...  Training Step: 85...  Training loss: 3.2633...  2.5697 sec/batch\n",
      "Epoch: 6/100...  Training Step: 86...  Training loss: 3.3537...  2.6106 sec/batch\n",
      "Epoch: 6/100...  Training Step: 87...  Training loss: 3.2811...  2.5185 sec/batch\n",
      "Epoch: 6/100...  Training Step: 88...  Training loss: 3.3154...  2.5540 sec/batch\n",
      "Epoch: 6/100...  Training Step: 89...  Training loss: 3.2826...  2.6295 sec/batch\n",
      "Epoch: 6/100...  Training Step: 90...  Training loss: 3.2942...  2.5487 sec/batch\n",
      "Epoch: 6/100...  Training Step: 91...  Training loss: 3.2975...  2.4617 sec/batch\n",
      "Epoch: 6/100...  Training Step: 92...  Training loss: 3.2772...  2.4344 sec/batch\n",
      "Epoch: 6/100...  Training Step: 93...  Training loss: 3.2635...  2.4345 sec/batch\n",
      "Epoch: 6/100...  Training Step: 94...  Training loss: 3.2459...  2.4235 sec/batch\n",
      "Epoch: 6/100...  Training Step: 95...  Training loss: 3.2270...  2.4081 sec/batch\n",
      "Epoch: 6/100...  Training Step: 96...  Training loss: 3.2292...  2.4108 sec/batch\n",
      "Epoch: 6/100...  Training Step: 97...  Training loss: 3.2012...  2.4883 sec/batch\n",
      "Epoch: 6/100...  Training Step: 98...  Training loss: 3.2362...  2.4131 sec/batch\n",
      "Epoch: 6/100...  Training Step: 99...  Training loss: 3.2092...  2.4235 sec/batch\n",
      "Epoch: 6/100...  Training Step: 100...  Training loss: 3.1904...  2.4180 sec/batch\n",
      "Epoch: 6/100...  Training Step: 101...  Training loss: 3.1810...  2.4266 sec/batch\n",
      "Epoch: 6/100...  Training Step: 102...  Training loss: 3.1744...  2.4021 sec/batch\n",
      "Epoch: 7/100...  Training Step: 103...  Training loss: 3.2456...  2.4054 sec/batch\n",
      "Epoch: 7/100...  Training Step: 104...  Training loss: 3.1657...  2.4390 sec/batch\n",
      "Epoch: 7/100...  Training Step: 105...  Training loss: 3.1753...  2.4215 sec/batch\n",
      "Epoch: 7/100...  Training Step: 106...  Training loss: 3.1871...  2.4210 sec/batch\n",
      "Epoch: 7/100...  Training Step: 107...  Training loss: 3.1723...  2.4066 sec/batch\n",
      "Epoch: 7/100...  Training Step: 108...  Training loss: 3.1821...  2.4151 sec/batch\n",
      "Epoch: 7/100...  Training Step: 109...  Training loss: 3.1635...  2.4251 sec/batch\n",
      "Epoch: 7/100...  Training Step: 110...  Training loss: 3.1455...  2.4165 sec/batch\n",
      "Epoch: 7/100...  Training Step: 111...  Training loss: 3.1220...  2.4210 sec/batch\n",
      "Epoch: 7/100...  Training Step: 112...  Training loss: 3.1159...  2.4191 sec/batch\n",
      "Epoch: 7/100...  Training Step: 113...  Training loss: 3.1162...  2.4141 sec/batch\n",
      "Epoch: 7/100...  Training Step: 114...  Training loss: 3.0870...  2.4937 sec/batch\n",
      "Epoch: 7/100...  Training Step: 115...  Training loss: 3.1248...  2.4320 sec/batch\n",
      "Epoch: 7/100...  Training Step: 116...  Training loss: 3.0963...  2.4225 sec/batch\n",
      "Epoch: 7/100...  Training Step: 117...  Training loss: 3.0981...  2.4141 sec/batch\n",
      "Epoch: 7/100...  Training Step: 118...  Training loss: 3.0707...  2.4315 sec/batch\n",
      "Epoch: 7/100...  Training Step: 119...  Training loss: 3.0916...  2.4170 sec/batch\n",
      "Epoch: 8/100...  Training Step: 120...  Training loss: 3.1398...  2.4156 sec/batch\n",
      "Epoch: 8/100...  Training Step: 121...  Training loss: 3.0864...  2.4699 sec/batch\n",
      "Epoch: 8/100...  Training Step: 122...  Training loss: 3.0816...  2.4941 sec/batch\n",
      "Epoch: 8/100...  Training Step: 123...  Training loss: 3.0906...  2.4071 sec/batch\n",
      "Epoch: 8/100...  Training Step: 124...  Training loss: 3.0770...  2.4370 sec/batch\n",
      "Epoch: 8/100...  Training Step: 125...  Training loss: 3.1008...  2.4352 sec/batch\n",
      "Epoch: 8/100...  Training Step: 126...  Training loss: 3.0601...  2.4185 sec/batch\n",
      "Epoch: 8/100...  Training Step: 127...  Training loss: 3.0449...  2.4195 sec/batch\n",
      "Epoch: 8/100...  Training Step: 128...  Training loss: 3.0467...  2.4145 sec/batch\n",
      "Epoch: 8/100...  Training Step: 129...  Training loss: 3.0267...  2.4196 sec/batch\n",
      "Epoch: 8/100...  Training Step: 130...  Training loss: 3.0333...  2.4135 sec/batch\n",
      "Epoch: 8/100...  Training Step: 131...  Training loss: 2.9968...  2.4296 sec/batch\n",
      "Epoch: 8/100...  Training Step: 132...  Training loss: 3.0424...  2.4312 sec/batch\n",
      "Epoch: 8/100...  Training Step: 133...  Training loss: 3.0143...  2.4238 sec/batch\n",
      "Epoch: 8/100...  Training Step: 134...  Training loss: 2.9937...  2.4205 sec/batch\n",
      "Epoch: 8/100...  Training Step: 135...  Training loss: 2.9861...  2.4172 sec/batch\n",
      "Epoch: 8/100...  Training Step: 136...  Training loss: 2.9978...  2.4195 sec/batch\n",
      "Epoch: 9/100...  Training Step: 137...  Training loss: 3.0614...  2.4155 sec/batch\n",
      "Epoch: 9/100...  Training Step: 138...  Training loss: 2.9808...  2.4165 sec/batch\n",
      "Epoch: 9/100...  Training Step: 139...  Training loss: 2.9772...  2.4160 sec/batch\n",
      "Epoch: 9/100...  Training Step: 140...  Training loss: 2.9852...  2.4205 sec/batch\n",
      "Epoch: 9/100...  Training Step: 141...  Training loss: 3.0153...  2.4350 sec/batch\n",
      "Epoch: 9/100...  Training Step: 142...  Training loss: 3.0091...  2.4285 sec/batch\n",
      "Epoch: 9/100...  Training Step: 143...  Training loss: 2.9698...  2.4125 sec/batch\n",
      "Epoch: 9/100...  Training Step: 144...  Training loss: 2.9639...  2.4046 sec/batch\n",
      "Epoch: 9/100...  Training Step: 145...  Training loss: 2.9562...  2.4265 sec/batch\n",
      "Epoch: 9/100...  Training Step: 146...  Training loss: 2.9398...  2.4262 sec/batch\n",
      "Epoch: 9/100...  Training Step: 147...  Training loss: 2.9381...  2.4998 sec/batch\n",
      "Epoch: 9/100...  Training Step: 148...  Training loss: 2.9057...  2.4310 sec/batch\n",
      "Epoch: 9/100...  Training Step: 149...  Training loss: 2.9625...  2.4135 sec/batch\n",
      "Epoch: 9/100...  Training Step: 150...  Training loss: 2.9296...  2.4245 sec/batch\n",
      "Epoch: 9/100...  Training Step: 151...  Training loss: 2.9207...  2.4320 sec/batch\n",
      "Epoch: 9/100...  Training Step: 152...  Training loss: 2.8999...  2.4177 sec/batch\n",
      "Epoch: 9/100...  Training Step: 153...  Training loss: 2.9147...  2.4420 sec/batch\n",
      "Epoch: 10/100...  Training Step: 154...  Training loss: 2.9767...  2.4306 sec/batch\n",
      "Epoch: 10/100...  Training Step: 155...  Training loss: 2.8928...  2.4166 sec/batch\n",
      "Epoch: 10/100...  Training Step: 156...  Training loss: 2.9053...  2.4175 sec/batch\n",
      "Epoch: 10/100...  Training Step: 157...  Training loss: 2.8992...  2.4335 sec/batch\n",
      "Epoch: 10/100...  Training Step: 158...  Training loss: 2.9060...  2.4205 sec/batch\n",
      "Epoch: 10/100...  Training Step: 159...  Training loss: 2.9239...  2.4320 sec/batch\n",
      "Epoch: 10/100...  Training Step: 160...  Training loss: 2.8853...  2.4277 sec/batch\n",
      "Epoch: 10/100...  Training Step: 161...  Training loss: 2.9112...  2.4560 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100...  Training Step: 162...  Training loss: 3.0487...  2.4200 sec/batch\n",
      "Epoch: 10/100...  Training Step: 163...  Training loss: 2.9695...  2.4446 sec/batch\n",
      "Epoch: 10/100...  Training Step: 164...  Training loss: 2.9061...  2.4360 sec/batch\n",
      "Epoch: 10/100...  Training Step: 165...  Training loss: 2.9018...  2.4400 sec/batch\n",
      "Epoch: 10/100...  Training Step: 166...  Training loss: 2.9434...  2.4300 sec/batch\n",
      "Epoch: 10/100...  Training Step: 167...  Training loss: 2.9065...  2.4315 sec/batch\n",
      "Epoch: 10/100...  Training Step: 168...  Training loss: 2.9034...  2.4290 sec/batch\n",
      "Epoch: 10/100...  Training Step: 169...  Training loss: 2.8793...  2.4235 sec/batch\n",
      "Epoch: 10/100...  Training Step: 170...  Training loss: 2.8920...  2.4166 sec/batch\n",
      "Epoch: 11/100...  Training Step: 171...  Training loss: 2.9464...  2.4270 sec/batch\n",
      "Epoch: 11/100...  Training Step: 172...  Training loss: 2.8618...  2.5327 sec/batch\n",
      "Epoch: 11/100...  Training Step: 173...  Training loss: 2.8691...  2.4634 sec/batch\n",
      "Epoch: 11/100...  Training Step: 174...  Training loss: 2.8660...  2.4235 sec/batch\n",
      "Epoch: 11/100...  Training Step: 175...  Training loss: 2.8785...  2.4290 sec/batch\n",
      "Epoch: 11/100...  Training Step: 176...  Training loss: 2.8940...  2.4241 sec/batch\n",
      "Epoch: 11/100...  Training Step: 177...  Training loss: 2.8504...  2.4344 sec/batch\n",
      "Epoch: 11/100...  Training Step: 178...  Training loss: 2.8289...  2.4380 sec/batch\n",
      "Epoch: 11/100...  Training Step: 179...  Training loss: 2.8229...  2.4480 sec/batch\n",
      "Epoch: 11/100...  Training Step: 180...  Training loss: 2.8149...  2.4275 sec/batch\n",
      "Epoch: 11/100...  Training Step: 181...  Training loss: 2.8002...  2.4290 sec/batch\n",
      "Epoch: 11/100...  Training Step: 182...  Training loss: 2.7837...  2.4457 sec/batch\n",
      "Epoch: 11/100...  Training Step: 183...  Training loss: 2.8232...  2.4260 sec/batch\n",
      "Epoch: 11/100...  Training Step: 184...  Training loss: 2.7989...  2.4320 sec/batch\n",
      "Epoch: 11/100...  Training Step: 185...  Training loss: 2.7844...  2.4265 sec/batch\n",
      "Epoch: 11/100...  Training Step: 186...  Training loss: 2.7473...  2.4244 sec/batch\n",
      "Epoch: 11/100...  Training Step: 187...  Training loss: 2.7780...  2.4580 sec/batch\n",
      "Epoch: 12/100...  Training Step: 188...  Training loss: 2.8211...  2.4395 sec/batch\n",
      "Epoch: 12/100...  Training Step: 189...  Training loss: 2.7465...  2.4440 sec/batch\n",
      "Epoch: 12/100...  Training Step: 190...  Training loss: 2.7519...  2.6499 sec/batch\n",
      "Epoch: 12/100...  Training Step: 191...  Training loss: 2.7588...  2.6863 sec/batch\n",
      "Epoch: 12/100...  Training Step: 192...  Training loss: 2.7684...  2.5532 sec/batch\n",
      "Epoch: 12/100...  Training Step: 193...  Training loss: 2.7720...  2.4531 sec/batch\n",
      "Epoch: 12/100...  Training Step: 194...  Training loss: 2.7410...  2.4290 sec/batch\n",
      "Epoch: 12/100...  Training Step: 195...  Training loss: 2.7261...  2.4125 sec/batch\n",
      "Epoch: 12/100...  Training Step: 196...  Training loss: 2.7096...  2.4375 sec/batch\n",
      "Epoch: 12/100...  Training Step: 197...  Training loss: 2.7003...  2.4973 sec/batch\n",
      "Epoch: 12/100...  Training Step: 198...  Training loss: 2.6899...  2.4345 sec/batch\n",
      "Epoch: 12/100...  Training Step: 199...  Training loss: 2.6679...  2.4350 sec/batch\n",
      "Epoch: 12/100...  Training Step: 200...  Training loss: 2.7168...  2.4343 sec/batch\n",
      "Epoch: 12/100...  Training Step: 201...  Training loss: 2.6892...  2.3112 sec/batch\n",
      "Epoch: 12/100...  Training Step: 202...  Training loss: 2.6745...  2.4467 sec/batch\n",
      "Epoch: 12/100...  Training Step: 203...  Training loss: 2.6447...  2.4339 sec/batch\n",
      "Epoch: 12/100...  Training Step: 204...  Training loss: 2.6716...  2.4330 sec/batch\n",
      "Epoch: 13/100...  Training Step: 205...  Training loss: 2.7142...  2.4290 sec/batch\n",
      "Epoch: 13/100...  Training Step: 206...  Training loss: 2.6347...  2.4520 sec/batch\n",
      "Epoch: 13/100...  Training Step: 207...  Training loss: 2.6453...  2.4485 sec/batch\n",
      "Epoch: 13/100...  Training Step: 208...  Training loss: 2.6509...  2.4405 sec/batch\n",
      "Epoch: 13/100...  Training Step: 209...  Training loss: 2.6525...  2.4567 sec/batch\n",
      "Epoch: 13/100...  Training Step: 210...  Training loss: 2.6613...  2.4340 sec/batch\n",
      "Epoch: 13/100...  Training Step: 211...  Training loss: 2.6294...  2.4350 sec/batch\n",
      "Epoch: 13/100...  Training Step: 212...  Training loss: 2.6278...  2.4435 sec/batch\n",
      "Epoch: 13/100...  Training Step: 213...  Training loss: 2.6162...  2.4462 sec/batch\n",
      "Epoch: 13/100...  Training Step: 214...  Training loss: 2.6111...  2.4335 sec/batch\n",
      "Epoch: 13/100...  Training Step: 215...  Training loss: 2.6050...  2.4390 sec/batch\n",
      "Epoch: 13/100...  Training Step: 216...  Training loss: 2.5857...  2.4480 sec/batch\n",
      "Epoch: 13/100...  Training Step: 217...  Training loss: 2.6159...  2.4376 sec/batch\n",
      "Epoch: 13/100...  Training Step: 218...  Training loss: 2.5940...  2.4295 sec/batch\n",
      "Epoch: 13/100...  Training Step: 219...  Training loss: 2.5909...  2.4305 sec/batch\n",
      "Epoch: 13/100...  Training Step: 220...  Training loss: 2.5595...  2.4359 sec/batch\n",
      "Epoch: 13/100...  Training Step: 221...  Training loss: 2.5977...  2.4313 sec/batch\n",
      "Epoch: 14/100...  Training Step: 222...  Training loss: 2.6439...  2.5033 sec/batch\n",
      "Epoch: 14/100...  Training Step: 223...  Training loss: 2.5640...  2.4355 sec/batch\n",
      "Epoch: 14/100...  Training Step: 224...  Training loss: 2.6035...  2.4330 sec/batch\n",
      "Epoch: 14/100...  Training Step: 225...  Training loss: 2.6947...  2.4475 sec/batch\n",
      "Epoch: 14/100...  Training Step: 226...  Training loss: 2.6227...  2.4365 sec/batch\n",
      "Epoch: 14/100...  Training Step: 227...  Training loss: 2.6352...  2.4505 sec/batch\n",
      "Epoch: 14/100...  Training Step: 228...  Training loss: 2.6009...  2.4280 sec/batch\n",
      "Epoch: 14/100...  Training Step: 229...  Training loss: 2.6006...  2.4285 sec/batch\n",
      "Epoch: 14/100...  Training Step: 230...  Training loss: 2.5908...  2.4259 sec/batch\n",
      "Epoch: 14/100...  Training Step: 231...  Training loss: 2.5759...  2.4529 sec/batch\n",
      "Epoch: 14/100...  Training Step: 232...  Training loss: 2.5758...  2.4475 sec/batch\n",
      "Epoch: 14/100...  Training Step: 233...  Training loss: 2.5394...  2.4390 sec/batch\n",
      "Epoch: 14/100...  Training Step: 234...  Training loss: 2.5917...  2.4470 sec/batch\n",
      "Epoch: 14/100...  Training Step: 235...  Training loss: 2.5808...  2.4320 sec/batch\n",
      "Epoch: 14/100...  Training Step: 236...  Training loss: 2.5628...  2.4340 sec/batch\n",
      "Epoch: 14/100...  Training Step: 237...  Training loss: 2.5386...  2.5323 sec/batch\n",
      "Epoch: 14/100...  Training Step: 238...  Training loss: 2.5751...  2.4250 sec/batch\n",
      "Epoch: 15/100...  Training Step: 239...  Training loss: 2.6216...  2.4450 sec/batch\n",
      "Epoch: 15/100...  Training Step: 240...  Training loss: 2.5473...  2.4310 sec/batch\n",
      "Epoch: 15/100...  Training Step: 241...  Training loss: 2.5510...  2.4634 sec/batch\n",
      "Epoch: 15/100...  Training Step: 242...  Training loss: 2.5544...  2.4410 sec/batch\n",
      "Epoch: 15/100...  Training Step: 243...  Training loss: 2.5565...  2.4420 sec/batch\n",
      "Epoch: 15/100...  Training Step: 244...  Training loss: 2.5786...  2.4370 sec/batch\n",
      "Epoch: 15/100...  Training Step: 245...  Training loss: 2.5584...  2.4296 sec/batch\n",
      "Epoch: 15/100...  Training Step: 246...  Training loss: 2.5548...  2.4709 sec/batch\n",
      "Epoch: 15/100...  Training Step: 247...  Training loss: 2.5363...  2.4760 sec/batch\n",
      "Epoch: 15/100...  Training Step: 248...  Training loss: 2.5378...  2.4400 sec/batch\n",
      "Epoch: 15/100...  Training Step: 249...  Training loss: 2.5219...  2.4310 sec/batch\n",
      "Epoch: 15/100...  Training Step: 250...  Training loss: 2.5159...  2.4371 sec/batch\n",
      "Epoch: 15/100...  Training Step: 251...  Training loss: 2.5388...  2.4495 sec/batch\n",
      "Epoch: 15/100...  Training Step: 252...  Training loss: 2.5267...  2.4445 sec/batch\n",
      "Epoch: 15/100...  Training Step: 253...  Training loss: 2.5111...  2.4310 sec/batch\n",
      "Epoch: 15/100...  Training Step: 254...  Training loss: 2.4969...  2.4375 sec/batch\n",
      "Epoch: 15/100...  Training Step: 255...  Training loss: 2.5359...  2.4415 sec/batch\n",
      "Epoch: 16/100...  Training Step: 256...  Training loss: 2.5790...  2.4280 sec/batch\n",
      "Epoch: 16/100...  Training Step: 257...  Training loss: 2.4953...  2.4250 sec/batch\n",
      "Epoch: 16/100...  Training Step: 258...  Training loss: 2.5166...  2.4338 sec/batch\n",
      "Epoch: 16/100...  Training Step: 259...  Training loss: 2.5143...  2.4355 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/100...  Training Step: 260...  Training loss: 2.5341...  2.4405 sec/batch\n",
      "Epoch: 16/100...  Training Step: 261...  Training loss: 2.5356...  2.4619 sec/batch\n",
      "Epoch: 16/100...  Training Step: 262...  Training loss: 2.5119...  2.4530 sec/batch\n",
      "Epoch: 16/100...  Training Step: 263...  Training loss: 2.5095...  2.4385 sec/batch\n",
      "Epoch: 16/100...  Training Step: 264...  Training loss: 2.5014...  2.4510 sec/batch\n",
      "Epoch: 16/100...  Training Step: 265...  Training loss: 2.4965...  2.4233 sec/batch\n",
      "Epoch: 16/100...  Training Step: 266...  Training loss: 2.4917...  2.4373 sec/batch\n",
      "Epoch: 16/100...  Training Step: 267...  Training loss: 2.4774...  2.4275 sec/batch\n",
      "Epoch: 16/100...  Training Step: 268...  Training loss: 2.5076...  2.4334 sec/batch\n",
      "Epoch: 16/100...  Training Step: 269...  Training loss: 2.4959...  2.4315 sec/batch\n",
      "Epoch: 16/100...  Training Step: 270...  Training loss: 2.4880...  2.4340 sec/batch\n",
      "Epoch: 16/100...  Training Step: 271...  Training loss: 2.4605...  2.4988 sec/batch\n",
      "Epoch: 16/100...  Training Step: 272...  Training loss: 2.5069...  2.4514 sec/batch\n",
      "Epoch: 17/100...  Training Step: 273...  Training loss: 2.5383...  2.4301 sec/batch\n",
      "Epoch: 17/100...  Training Step: 274...  Training loss: 2.4694...  2.4265 sec/batch\n",
      "Epoch: 17/100...  Training Step: 275...  Training loss: 2.4898...  2.4275 sec/batch\n",
      "Epoch: 17/100...  Training Step: 276...  Training loss: 2.4882...  2.4380 sec/batch\n",
      "Epoch: 17/100...  Training Step: 277...  Training loss: 2.5128...  2.4350 sec/batch\n",
      "Epoch: 17/100...  Training Step: 278...  Training loss: 2.5135...  2.4510 sec/batch\n",
      "Epoch: 17/100...  Training Step: 279...  Training loss: 2.4937...  2.4380 sec/batch\n",
      "Epoch: 17/100...  Training Step: 280...  Training loss: 2.4850...  2.4310 sec/batch\n",
      "Epoch: 17/100...  Training Step: 281...  Training loss: 2.4867...  2.4235 sec/batch\n",
      "Epoch: 17/100...  Training Step: 282...  Training loss: 2.4798...  2.4205 sec/batch\n",
      "Epoch: 17/100...  Training Step: 283...  Training loss: 2.4726...  2.4370 sec/batch\n",
      "Epoch: 17/100...  Training Step: 284...  Training loss: 2.4523...  2.4310 sec/batch\n",
      "Epoch: 17/100...  Training Step: 285...  Training loss: 2.4875...  2.4425 sec/batch\n",
      "Epoch: 17/100...  Training Step: 286...  Training loss: 2.4674...  2.6325 sec/batch\n",
      "Epoch: 17/100...  Training Step: 287...  Training loss: 2.4637...  2.5894 sec/batch\n",
      "Epoch: 17/100...  Training Step: 288...  Training loss: 2.4352...  2.5422 sec/batch\n",
      "Epoch: 17/100...  Training Step: 289...  Training loss: 2.4759...  2.4569 sec/batch\n",
      "Epoch: 18/100...  Training Step: 290...  Training loss: 2.5059...  2.7021 sec/batch\n",
      "Epoch: 18/100...  Training Step: 291...  Training loss: 2.4311...  2.7223 sec/batch\n",
      "Epoch: 18/100...  Training Step: 292...  Training loss: 2.4578...  2.7532 sec/batch\n",
      "Epoch: 18/100...  Training Step: 293...  Training loss: 2.4573...  2.6021 sec/batch\n",
      "Epoch: 18/100...  Training Step: 294...  Training loss: 2.4739...  2.5886 sec/batch\n",
      "Epoch: 18/100...  Training Step: 295...  Training loss: 2.4770...  2.6131 sec/batch\n",
      "Epoch: 18/100...  Training Step: 296...  Training loss: 2.4630...  2.5454 sec/batch\n",
      "Epoch: 18/100...  Training Step: 297...  Training loss: 2.4614...  2.4729 sec/batch\n",
      "Epoch: 18/100...  Training Step: 298...  Training loss: 2.4496...  2.4524 sec/batch\n",
      "Epoch: 18/100...  Training Step: 299...  Training loss: 2.4496...  2.5009 sec/batch\n",
      "Epoch: 18/100...  Training Step: 300...  Training loss: 2.4371...  2.4734 sec/batch\n",
      "Epoch: 18/100...  Training Step: 301...  Training loss: 2.4205...  2.4579 sec/batch\n",
      "Epoch: 18/100...  Training Step: 302...  Training loss: 2.4538...  2.4549 sec/batch\n",
      "Epoch: 18/100...  Training Step: 303...  Training loss: 2.4354...  2.4697 sec/batch\n",
      "Epoch: 18/100...  Training Step: 304...  Training loss: 2.4321...  2.4542 sec/batch\n",
      "Epoch: 18/100...  Training Step: 305...  Training loss: 2.3931...  2.4584 sec/batch\n",
      "Epoch: 18/100...  Training Step: 306...  Training loss: 2.4583...  2.4629 sec/batch\n",
      "Epoch: 19/100...  Training Step: 307...  Training loss: 2.4956...  2.4504 sec/batch\n",
      "Epoch: 19/100...  Training Step: 308...  Training loss: 2.4245...  2.4604 sec/batch\n",
      "Epoch: 19/100...  Training Step: 309...  Training loss: 2.4402...  2.4577 sec/batch\n",
      "Epoch: 19/100...  Training Step: 310...  Training loss: 2.4382...  2.4494 sec/batch\n",
      "Epoch: 19/100...  Training Step: 311...  Training loss: 2.4564...  2.4719 sec/batch\n",
      "Epoch: 19/100...  Training Step: 312...  Training loss: 2.4690...  2.4544 sec/batch\n",
      "Epoch: 19/100...  Training Step: 313...  Training loss: 2.4479...  2.4597 sec/batch\n",
      "Epoch: 19/100...  Training Step: 314...  Training loss: 2.4399...  2.4450 sec/batch\n",
      "Epoch: 19/100...  Training Step: 315...  Training loss: 2.4486...  2.4742 sec/batch\n",
      "Epoch: 19/100...  Training Step: 316...  Training loss: 2.4386...  2.4569 sec/batch\n",
      "Epoch: 19/100...  Training Step: 317...  Training loss: 2.4210...  2.4607 sec/batch\n",
      "Epoch: 19/100...  Training Step: 318...  Training loss: 2.4070...  2.4629 sec/batch\n",
      "Epoch: 19/100...  Training Step: 319...  Training loss: 2.4345...  2.4572 sec/batch\n",
      "Epoch: 19/100...  Training Step: 320...  Training loss: 2.4338...  2.5287 sec/batch\n",
      "Epoch: 19/100...  Training Step: 321...  Training loss: 2.4130...  2.4539 sec/batch\n",
      "Epoch: 19/100...  Training Step: 322...  Training loss: 2.3875...  2.4621 sec/batch\n",
      "Epoch: 19/100...  Training Step: 323...  Training loss: 2.4375...  2.4698 sec/batch\n",
      "Epoch: 20/100...  Training Step: 324...  Training loss: 2.4683...  2.4559 sec/batch\n",
      "Epoch: 20/100...  Training Step: 325...  Training loss: 2.4062...  2.4510 sec/batch\n",
      "Epoch: 20/100...  Training Step: 326...  Training loss: 2.4213...  2.4873 sec/batch\n",
      "Epoch: 20/100...  Training Step: 327...  Training loss: 2.4239...  2.4525 sec/batch\n",
      "Epoch: 20/100...  Training Step: 328...  Training loss: 2.4518...  2.4609 sec/batch\n",
      "Epoch: 20/100...  Training Step: 329...  Training loss: 2.4392...  2.4849 sec/batch\n",
      "Epoch: 20/100...  Training Step: 330...  Training loss: 2.4208...  2.4724 sec/batch\n",
      "Epoch: 20/100...  Training Step: 331...  Training loss: 2.4159...  2.5235 sec/batch\n",
      "Epoch: 20/100...  Training Step: 332...  Training loss: 2.4237...  2.4485 sec/batch\n",
      "Epoch: 20/100...  Training Step: 333...  Training loss: 2.4128...  2.4659 sec/batch\n",
      "Epoch: 20/100...  Training Step: 334...  Training loss: 2.4000...  2.4589 sec/batch\n",
      "Epoch: 20/100...  Training Step: 335...  Training loss: 2.3854...  2.4636 sec/batch\n",
      "Epoch: 20/100...  Training Step: 336...  Training loss: 2.4133...  2.4686 sec/batch\n",
      "Epoch: 20/100...  Training Step: 337...  Training loss: 2.4033...  2.4555 sec/batch\n",
      "Epoch: 20/100...  Training Step: 338...  Training loss: 2.3982...  2.4510 sec/batch\n",
      "Epoch: 20/100...  Training Step: 339...  Training loss: 2.3691...  2.4560 sec/batch\n",
      "Epoch: 20/100...  Training Step: 340...  Training loss: 2.4190...  2.4549 sec/batch\n",
      "Epoch: 21/100...  Training Step: 341...  Training loss: 2.4481...  2.4524 sec/batch\n",
      "Epoch: 21/100...  Training Step: 342...  Training loss: 2.3821...  2.4494 sec/batch\n",
      "Epoch: 21/100...  Training Step: 343...  Training loss: 2.3975...  2.4594 sec/batch\n",
      "Epoch: 21/100...  Training Step: 344...  Training loss: 2.3973...  2.4589 sec/batch\n",
      "Epoch: 21/100...  Training Step: 345...  Training loss: 2.4087...  2.5338 sec/batch\n",
      "Epoch: 21/100...  Training Step: 346...  Training loss: 2.4228...  2.4679 sec/batch\n",
      "Epoch: 21/100...  Training Step: 347...  Training loss: 2.3979...  2.4779 sec/batch\n",
      "Epoch: 21/100...  Training Step: 348...  Training loss: 2.3972...  2.4669 sec/batch\n",
      "Epoch: 21/100...  Training Step: 349...  Training loss: 2.3918...  2.4744 sec/batch\n",
      "Epoch: 21/100...  Training Step: 350...  Training loss: 2.3817...  2.4544 sec/batch\n",
      "Epoch: 21/100...  Training Step: 351...  Training loss: 2.3749...  2.4838 sec/batch\n",
      "Epoch: 21/100...  Training Step: 352...  Training loss: 2.3696...  2.4709 sec/batch\n",
      "Epoch: 21/100...  Training Step: 353...  Training loss: 2.3966...  2.4605 sec/batch\n",
      "Epoch: 21/100...  Training Step: 354...  Training loss: 2.3783...  2.4569 sec/batch\n",
      "Epoch: 21/100...  Training Step: 355...  Training loss: 2.3745...  2.4614 sec/batch\n",
      "Epoch: 21/100...  Training Step: 356...  Training loss: 2.3453...  2.4534 sec/batch\n",
      "Epoch: 21/100...  Training Step: 357...  Training loss: 2.4066...  2.4824 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/100...  Training Step: 358...  Training loss: 2.4236...  2.5422 sec/batch\n",
      "Epoch: 22/100...  Training Step: 359...  Training loss: 2.3552...  2.5168 sec/batch\n",
      "Epoch: 22/100...  Training Step: 360...  Training loss: 2.3838...  2.4789 sec/batch\n",
      "Epoch: 22/100...  Training Step: 361...  Training loss: 2.3707...  2.4707 sec/batch\n",
      "Epoch: 22/100...  Training Step: 362...  Training loss: 2.3924...  2.4707 sec/batch\n",
      "Epoch: 22/100...  Training Step: 363...  Training loss: 2.3980...  2.4589 sec/batch\n",
      "Epoch: 22/100...  Training Step: 364...  Training loss: 2.3915...  2.4649 sec/batch\n",
      "Epoch: 22/100...  Training Step: 365...  Training loss: 2.3886...  2.4719 sec/batch\n",
      "Epoch: 22/100...  Training Step: 366...  Training loss: 2.3929...  2.4734 sec/batch\n",
      "Epoch: 22/100...  Training Step: 367...  Training loss: 2.3770...  2.4569 sec/batch\n",
      "Epoch: 22/100...  Training Step: 368...  Training loss: 2.3628...  2.4694 sec/batch\n",
      "Epoch: 22/100...  Training Step: 369...  Training loss: 2.3620...  2.5233 sec/batch\n",
      "Epoch: 22/100...  Training Step: 370...  Training loss: 2.3724...  2.4610 sec/batch\n",
      "Epoch: 22/100...  Training Step: 371...  Training loss: 2.3764...  2.4689 sec/batch\n",
      "Epoch: 22/100...  Training Step: 372...  Training loss: 2.3676...  2.4734 sec/batch\n",
      "Epoch: 22/100...  Training Step: 373...  Training loss: 2.3302...  2.4769 sec/batch\n",
      "Epoch: 22/100...  Training Step: 374...  Training loss: 2.3900...  2.4664 sec/batch\n",
      "Epoch: 23/100...  Training Step: 375...  Training loss: 2.4103...  2.4649 sec/batch\n",
      "Epoch: 23/100...  Training Step: 376...  Training loss: 2.3550...  2.4595 sec/batch\n",
      "Epoch: 23/100...  Training Step: 377...  Training loss: 2.3699...  2.4629 sec/batch\n",
      "Epoch: 23/100...  Training Step: 378...  Training loss: 2.3600...  2.4754 sec/batch\n",
      "Epoch: 23/100...  Training Step: 379...  Training loss: 2.3883...  2.4609 sec/batch\n",
      "Epoch: 23/100...  Training Step: 380...  Training loss: 2.3854...  2.4565 sec/batch\n",
      "Epoch: 23/100...  Training Step: 381...  Training loss: 2.3728...  2.4739 sec/batch\n",
      "Epoch: 23/100...  Training Step: 382...  Training loss: 2.3649...  2.4514 sec/batch\n",
      "Epoch: 23/100...  Training Step: 383...  Training loss: 2.3713...  2.4626 sec/batch\n",
      "Epoch: 23/100...  Training Step: 384...  Training loss: 2.3498...  2.4539 sec/batch\n",
      "Epoch: 23/100...  Training Step: 385...  Training loss: 2.3496...  2.4669 sec/batch\n",
      "Epoch: 23/100...  Training Step: 386...  Training loss: 2.3345...  2.4589 sec/batch\n",
      "Epoch: 23/100...  Training Step: 387...  Training loss: 2.3535...  2.4624 sec/batch\n",
      "Epoch: 23/100...  Training Step: 388...  Training loss: 2.3618...  2.4634 sec/batch\n",
      "Epoch: 23/100...  Training Step: 389...  Training loss: 2.3420...  2.4809 sec/batch\n",
      "Epoch: 23/100...  Training Step: 390...  Training loss: 2.3122...  2.4764 sec/batch\n",
      "Epoch: 23/100...  Training Step: 391...  Training loss: 2.3655...  2.4764 sec/batch\n",
      "Epoch: 24/100...  Training Step: 392...  Training loss: 2.3932...  2.4674 sec/batch\n",
      "Epoch: 24/100...  Training Step: 393...  Training loss: 2.3273...  2.4580 sec/batch\n",
      "Epoch: 24/100...  Training Step: 394...  Training loss: 2.3436...  2.5781 sec/batch\n",
      "Epoch: 24/100...  Training Step: 395...  Training loss: 2.3434...  2.4794 sec/batch\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "# Сохраняться каждый N итераций\n",
    "save_every_n = 200\n",
    "\n",
    "model = CharRNN(len(vocab), batch_size=batch_size, num_steps=num_steps,\n",
    "                lstm_size=lstm_size, num_layers=num_layers, \n",
    "                learning_rate=learning_rate)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Можно раскомментировать строчку ниже и продолжить обучение с checkpoint'а\n",
    "    #saver.restore(sess, 'checkpoints/______.ckpt')\n",
    "    counter = 0\n",
    "    for e in range(epochs):\n",
    "        # Обучаем сеть\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        loss = 0\n",
    "        for x, y in get_batches(encoded, batch_size, num_steps):\n",
    "            counter += 1\n",
    "            start = time.time()\n",
    "            feed = {model.inputs: x,\n",
    "                    model.targets: y,\n",
    "                    model.keep_prob: keep_prob,\n",
    "                    model.initial_state: new_state}\n",
    "            batch_loss, new_state, _ = sess.run([model.loss, \n",
    "                                                 model.final_state, \n",
    "                                                 model.optimizer], \n",
    "                                                 feed_dict=feed)\n",
    "            \n",
    "            end = time.time()\n",
    "            print('Epoch: {}/{}... '.format(e+1, epochs),\n",
    "                  'Training Step: {}... '.format(counter),\n",
    "                  'Training loss: {:.4f}... '.format(batch_loss),\n",
    "                  '{:.4f} sec/batch'.format((end-start)))\n",
    "        \n",
    "            if (counter % save_every_n == 0):\n",
    "                saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))\n",
    "    \n",
    "    saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T12:52:49.208066Z",
     "start_time": "2020-03-22T12:52:49.203080Z"
    }
   },
   "outputs": [],
   "source": [
    "def pick_top_n(preds, vocab_size, top_n=5):\n",
    "    p = np.squeeze(preds)\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    c = np.random.choice(vocab_size, 1, p=p)[0]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T12:52:49.551110Z",
     "start_time": "2020-03-22T12:52:49.544617Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample(checkpoint, n_samples, lstm_size, vocab_size, prime=\"Мой дядя самых честных правил,Когда не в шутку занемог,\"):\n",
    "    samples = [c for c in prime]\n",
    "    model = CharRNN(len(vocab), lstm_size=lstm_size, sampling=True)\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, checkpoint)\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        for c in prime:\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0,0] = vocab_to_int[c]\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "        c = pick_top_n(preds, len(vocab))\n",
    "        samples.append(int_to_vocab[c])\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            x[0,0] = c\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "            c = pick_top_n(preds, len(vocab))\n",
    "            samples.append(int_to_vocab[c])\n",
    "        \n",
    "    return ''.join(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T12:52:50.040623Z",
     "start_time": "2020-03-22T12:52:50.035612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_checkpoint_path: \"checkpoints\\\\i400_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i200_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints\\\\i400_l512.ckpt\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.get_checkpoint_state('checkpoints')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T12:52:55.667612Z",
     "start_time": "2020-03-22T12:52:50.448109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-18-8c6cbb068115>:14: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-18-8c6cbb068115>:21: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-22-54e7f495548d>:27: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x0000020207255F88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x0000020207255F88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x0000020207255F88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x0000020207255F88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x0000020203FDBEC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x0000020203FDBEC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x0000020203FDBEC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x0000020203FDBEC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x00000202068990C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x00000202068990C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x00000202068990C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x00000202068990C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-20-97c11d64dd2a>:17: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/i400_l512.ckpt\n",
      "Мой дядя самых честных правил,Когда не в шутку занемог,\n",
      "\n",
      "Ка тов проставой ностарини\n",
      "\n",
      "С вали м серемнае плазоны\n",
      "\n",
      "Владена воресто налавот\n",
      "\n",
      "В сарамет, поско нем она,\n",
      "\n",
      "И, полонаним страдить,\n",
      "\n",
      "От сти скорони на сторат,\n",
      "\n",
      "Носто волинь о стору нел\n",
      "\n",
      "И, ват пиредней пустиный,\n",
      "\n",
      "И стедно в сольний одолит,\n",
      "\n",
      "И петья, вали прадельный,\n",
      "\n",
      "И, веде нограны полед,\n",
      "\n",
      "Стодна, кут онаметь, вало,\n",
      "\n",
      "И воралит но волатьяна,\n",
      "\n",
      "В весь мусте сневениесь свел.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "XVI\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "О ведной не но ват вастоль.\n",
      "\n",
      "Тутьяно строны мит предой;\n",
      "\n",
      "О вестилинась вестой ней\n",
      "\n",
      "Своре ведерене велеста\n",
      "\n",
      "И сталесь ни подане муть!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "XVI\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ни о мет верень, но васконей,\n",
      "\n",
      "И ный волина в сомей поро,\n",
      "\n",
      "Но варедны пругони милет.\n",
      "\n",
      "Вомилель намони сврегон,\n",
      "\n",
      "Вскаль и ветний свородина\n",
      "\n",
      "Патоли в преску ный пели,\n",
      "\n",
      "Стрений сень, порудим востий,\n",
      "\n",
      "Приде вом вел стресный ворнай;\n",
      "\n",
      "И торена ворилась намо,\n",
      "\n",
      "И сет бестине ногрогу.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LVV\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Вы село пелиска сногодий,\n",
      "\n",
      "И в примолнив совой стиване,\n",
      "\n",
      "И влани в намоне подень,\n",
      "\n",
      "Во воли стомо став ну дом\n",
      "\n",
      "Он вореть нам новой недин,\n",
      "\n",
      "Ни стомне стридола негола,\n",
      "\n",
      "Кас острим \n"
     ]
    }
   ],
   "source": [
    "checkpoint = 'checkpoints/i400_l512.ckpt'\n",
    "samp = sample(checkpoint, 1000, lstm_size, len(vocab))\n",
    "print(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
